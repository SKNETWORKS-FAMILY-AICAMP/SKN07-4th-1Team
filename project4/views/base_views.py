from django.shortcuts import render, get_object_or_404, redirect
from django.http import HttpResponse
# from ..models import Question, Answer
from django.utils import timezone
from django.contrib.auth.decorators import login_required 
from django.core.paginator import Paginator
from django.db.models import Q
from django.http import JsonResponse
import os
import json
import openai
import pandas as pd
from langchain.schema import Document, messages_from_dict
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.schema import HumanMessage, AIMessage, SystemMessage

# Create your views here.
# from ..forms import QuestionForm, AnswerForm
## ---------- ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° ì²´í¬
db_path = './data/'
db_initialized = os.path.exists(db_path)

# ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ë§Œ ë²¡í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
db = Chroma(persist_directory=db_path, embedding_function=embeddings)

if not db_initialized or db._collection.count() == 0:  # DB í´ë”ê°€ ì—†ê±°ë‚˜, DBê°€ ë¹„ì–´ ìˆëŠ” ê²½ìš°
    print("ğŸ”„ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„± ì¤‘...")

    # í˜„ì¬ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ (base_views.pyê°€ ìˆëŠ” í´ë”)
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    # CSV íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
    csv_path = os.path.join(BASE_DIR, 'data', 'suksoDF.csv')
    # CSV íŒŒì¼ ì½ê¸°
    df = pd.read_csv(csv_path)

    # ë²¡í„°í™” ëœ ë°ì´í„°ë¥¼ DBì— ì €ì¥
    documents = [
        Document(
            page_content=f"ê´€ê´‘ì§€ëª…: {row['name']} ì£¼ì†Œ: {row['address']}, ì†Œê°œ: {row['overview']}, ìˆ™ì†Œì •ë³´: {row['generalInfo']}, ê°ì‹¤ì •ë³´: {row['roomInfo']}, ìˆ™ì†Œì´ë¯¸ì§€: {row['imglink']}",
            metadata={"id": idx}
        ) for idx, row in df.iterrows()
    ]

    # ë¬¸ì„œ ë°°ì¹˜ë¥¼ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜
    def batch_documents(documents, batch_size):
        for i in range(0, len(documents), batch_size):
            yield documents[i:i + batch_size]

    # ë°°ì¹˜ í¬ê¸° ì„¤ì •
    batch_size = 100

    # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
    for batch in batch_documents(documents, batch_size):
        try:
            db.add_documents(batch)
            db.persist()
            print(f"âœ… Batch of size {batch_size} added successfully.")
        except Exception as e:
            print(f"âŒ An error occurred: {e}")
else:
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©° ë²¡í„°ê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")


# LLM ì„¤ì •
llm = ChatOpenAI(
    model='gpt-4o-2024-08-06'
)

# ì±—ë´‡ ì‘ë‹µ ìƒì„±
def get_answer_from_db(user_query, chat_history):
    results = db.similarity_search(user_query, k=5)

    if not results:
        return "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context = "\n".join([result.page_content for result in results])

    messages = chat_history.copy()
    messages.append(HumanMessage(content=f"ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\n\n   \
    ì°¸ê³ í•  ì •ë³´:\n{context}\n\nì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”.  \
    {user_query}ì˜ ìš”êµ¬ì‚¬í•­ê³¼ {context}\n\nì˜ ì •ë³´ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ì œì™¸í•˜ê³  ë‹µë³€í•´ ì£¼ì„¸ìš”. \
    {context}ì— ì´ë¯¸ì§€ ë§í¬ê°€ ìˆìœ¼ë©´, ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ í¬ê¸°ë¥¼ 50% ë¹„ìœ¨ë¡œ ë³€ê²½í•´ ì¶œë ¥í•´ì£¼ì„¸ìš”. "))

    response = llm(messages)
    return response.content

# RetrievalQA ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm, 
    chain_type="map_reduce", 
    retriever=db.as_retriever()
)

# ë©”ì¸í˜ì´ì§€ 
def index(request):
   
    return render(request, 'project4/main_chat.html')

# Ajax ìš”ì²­ì„ ë°›ì•„ì„œ LLM ë‹µë³€ ë°˜í™˜
def chat_response(request):
    if request.method == "POST":
        user_query = request.POST.get("query", "")
        # print(f'user_query : {user_query}')
        if not user_query:
            return JsonResponse({"error": "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."}, status=400)

        chat_history = []  # ì„¸ì…˜ì— ì €ì¥í•˜ë ¤ë©´ request.session í™œìš© ê°€ëŠ¥
        response = get_answer_from_db(user_query, chat_history)
        # print(f"response : {response}")
        return JsonResponse({"response": response})

    return JsonResponse({"error": "ì˜ëª»ëœ ìš”ì²­ ë°©ì‹ì…ë‹ˆë‹¤."}, status=400)